{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREDITS https://jackmckew.dev/sentiment-analysis-text-cleaning-in-python-with-vader.html\n",
    "#on code for consolidating top sentiments in one video dataset\n",
    "#then modify code to consolidate top videos with highest overall positive sentiments instead\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = '_O2sg-PGhEg' #video id of df1 in get_sentiment_vader.ipynb \n",
    "#text_data = pd.read_table('original_rt_snippets.txt',header=None) \n",
    "\n",
    "text_data = pd.read_json(f'../results/crashcourse/{video_id}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text:str, analyserobj,desired_type:str='pos'):\n",
    "    # Get sentiment from text\n",
    "    sentiment_score = analyserobj.polarity_scores(text)\n",
    "    return sentiment_score[desired_type]\n",
    "\n",
    "\n",
    "# Get Sentiment scores\n",
    "def get_sentiment_scores(df,data_column):\n",
    "    sentimentlist = [] #empty list should be here because if looped through all videos of a channel, sentimentlist should renew\n",
    "    \n",
    "    #df[f'{data_column} negative'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,analyzer,'neg'))\n",
    "    df['negative'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,analyzer,'neg'))\n",
    "    df['neutral'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,analyzer,'neu'))\n",
    "    df['positive'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,analyzer,'pos'))\n",
    "    df['compound'] = df[data_column].astype(str).apply(lambda x: get_sentiment(x,analyzer,'compound'))\n",
    "    \n",
    "    for comp in df['compound']:\n",
    "        if comp >= 0.05:\n",
    "            sentiment = 'positive'\n",
    "        elif comp <= -0.05:\n",
    "            sentiment = 'negative'\n",
    "        else:\n",
    "            sentiment = 'neutral'\n",
    "            \n",
    "        sentimentlist.append(sentiment)\n",
    "\n",
    "    df['sentiment'] = sentimentlist\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sentiment = get_sentiment_scores(text_data, 'comment_text')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_by</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_date</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sam JD</td>\n",
       "      <td>awesome host.. thank u so much</td>\n",
       "      <td>2022-07-14T09:38:00Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.7650</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Franzi Z</td>\n",
       "      <td>I love this series more with every episode I w...</td>\n",
       "      <td>2020-06-18T17:26:03Z</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.9440</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wade Allen</td>\n",
       "      <td>When I see images or renderings of super clust...</td>\n",
       "      <td>2020-06-17T17:46:52Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.5396</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Susurrus</td>\n",
       "      <td>It&amp;#39;s kinda like a video game where you try...</td>\n",
       "      <td>2020-06-10T12:41:45Z</td>\n",
       "      <td>1</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.8821</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eugene Scott</td>\n",
       "      <td>Can someone shed some light on why a super mas...</td>\n",
       "      <td>2020-06-06T00:10:48Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.4215</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>Somillian</td>\n",
       "      <td>Under 301 club.</td>\n",
       "      <td>2015-11-05T22:26:29Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>Mythri</td>\n",
       "      <td>First Like LOLOL</td>\n",
       "      <td>2015-11-05T22:24:14Z</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>Get Fixed</td>\n",
       "      <td>second</td>\n",
       "      <td>2015-11-05T22:23:58Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>ZeroKelvin</td>\n",
       "      <td>Second!</td>\n",
       "      <td>2015-11-05T22:23:57Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>BDogg Volz</td>\n",
       "      <td>F1RST!</td>\n",
       "      <td>2015-11-05T22:23:19Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1375 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        comment_by                                       comment_text  \\\n",
       "0           sam JD                     awesome host.. thank u so much   \n",
       "1         Franzi Z  I love this series more with every episode I w...   \n",
       "2       Wade Allen  When I see images or renderings of super clust...   \n",
       "3         Susurrus  It&#39;s kinda like a video game where you try...   \n",
       "4     Eugene Scott  Can someone shed some light on why a super mas...   \n",
       "...            ...                                                ...   \n",
       "1370     Somillian                                    Under 301 club.   \n",
       "1371        Mythri                                   First Like LOLOL   \n",
       "1372     Get Fixed                                             second   \n",
       "1373    ZeroKelvin                                            Second!   \n",
       "1374    BDogg Volz                                             F1RST!   \n",
       "\n",
       "              comment_date  likes_count  negative  neutral  positive  \\\n",
       "0     2022-07-14T09:38:00Z            1     0.000    0.377     0.623   \n",
       "1     2020-06-18T17:26:03Z            4     0.000    0.499     0.501   \n",
       "2     2020-06-17T17:46:52Z            0     0.042    0.887     0.071   \n",
       "3     2020-06-10T12:41:45Z            1     0.057    0.698     0.245   \n",
       "4     2020-06-06T00:10:48Z            0     0.084    0.760     0.156   \n",
       "...                    ...          ...       ...      ...       ...   \n",
       "1370  2015-11-05T22:26:29Z            2     0.000    1.000     0.000   \n",
       "1371  2015-11-05T22:24:14Z            2     0.000    0.444     0.556   \n",
       "1372  2015-11-05T22:23:58Z            0     0.000    1.000     0.000   \n",
       "1373  2015-11-05T22:23:57Z            0     0.000    1.000     0.000   \n",
       "1374  2015-11-05T22:23:19Z            0     0.000    1.000     0.000   \n",
       "\n",
       "      compound sentiment  \n",
       "0       0.7650  positive  \n",
       "1       0.9440  positive  \n",
       "2       0.5396  positive  \n",
       "3       0.8821  positive  \n",
       "4       0.4215  positive  \n",
       "...        ...       ...  \n",
       "1370    0.0000   neutral  \n",
       "1371    0.3612  positive  \n",
       "1372    0.0000   neutral  \n",
       "1373    0.0000   neutral  \n",
       "1374    0.0000   neutral  \n",
       "\n",
       "[1375 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_n_reviews(df,data_column,number_of_rows):\n",
    "\n",
    "    for index,row in df.nlargest(number_of_rows,data_column).iterrows():\n",
    "        #print(f\"Score: {row[data_column]}, Review: {row[0]}\")\n",
    "        print(f\"Score: {row[data_column]}, Comment: {row['comment_text']}\")\n",
    "        \n",
    "\n",
    "    # video_id = '_tULRch1PRQ'\n",
    "    # if totalpositivesentiment2 > totalnegativesentiment2 and totalneutralsentiment2:\n",
    "    #     print('df2 video is overall highly positively acclaimed')\n",
    "    #     print(f'recommend https://www.youtube.com/watch?v={video_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9889, Comment: Thank you very much, Phil Plait and the others there at <i>Crash Course</i> Astronomy, for making this video! Wow, the Universe really is amazing! I did know about galaxies before watching this video but I did not know about clusters and superclusters. 100 000 000 000 galaxies! Wow, thatâ€™s a pretty big number. Itâ€™s only a shame that we only will be able visit so few of them...Anyway, quasars are also splendid, fascinating! Thank you for making this video!<br><br>I do have a question, though. You mentioned that there are a number of ways to classify and group galaxies together, but only talked about two grouping them together based on shape (spiral, elliptical, irregular etc.) and based on energy-output (active, non-active and quasars). So galaxies are really huge, but how massive are there? How do you group them together based on mass? How massive are galaxies?\n",
      "Score: 0.9842, Comment: OK.<br>So I guess I&#39;m gonna rewatch this whole serie from the beginning before watching future episodes because :<br>1. It&#39;s so damn good and interesting. Phil sure knows how to share his passion. I already knew about the Hubble deep field, but my neck and arm hairs stood up anyway (and I felt like Phil&#39;s did the same ;).<br>2. There is way too much information and the numbers are way too big for me to understand and remember everything. So now, I&#39;m taking notes !<br><br>I&#39;d like to thank Phil for sharing his passion with such interest, and all the team for making these good quality videos for everyone.\n",
      "Score: 0.9774, Comment: Holy crap Phil, your dedication and enthusiasm are truly contagious. Every single episode you write and host is not only extremely entertaining to watch but also deeply mind expanding. You have a gift mate, please never let go, you are doing an immensely important job teaching and spreading this subject.<br><br>The day when every single person on our tiny planet is aware of the contents shared in this series, Earth will be an awesome place to live in. We should all help that day come as fast as possible.<br><br>Already waiting for the next episode :)\n",
      "Score: 0.9719, Comment: Great work crash course. I watch every section of yours and it is amazing. Love it. Please upload geography videos, geomorphology, climatology and oceanography in particular. If you can do that, it will be fantastic. Thank you, all the best.\n",
      "Score: 0.9709, Comment: Phil, <br>your series has inspired me to become an amateur astronomer. I am fascinated with the content you put out every week and always look forward to your videos. I&#39;m hoping you can recommend a good stater telescope... I have done a lot of research and am currently leaning towards the Celestrone 6SE (roughly $1000.00 CAD). If you have time to respond I would love your input (or any other knowledgeable astronomers on this comment section) . <br>Keep up the excellent work!\n"
     ]
    }
   ],
   "source": [
    "#below are the 5 most positive comments in 1 video\n",
    "#how to modify functions to print out 5 most positive videos instead\n",
    "\n",
    "print_top_n_reviews(text_sentiment,'compound', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 1.0, Comment: Lol\n",
      "Score: 1.0, Comment: Brilliant\n",
      "Score: 1.0, Comment: awesome\n",
      "Score: 1.0, Comment: Nice\n",
      "Score: 1.0, Comment: amazing!!!!!!\n"
     ]
    }
   ],
   "source": [
    "#according to vader github and jack mckew blog, compound scoring is independent, more useful and so it has more meaningful comments and has more depth than positive column contains degrees of sentiments that is dependent on negative and neutral \n",
    "print_top_n_reviews(text_sentiment,'positive', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#refer to get_top10_sentiment file's loop through all of channel's videos and normalizing every video's comments' unidimensional positives\n",
    "#then change top10 (by views or likes) dataframe code to top10 (by largest percentages of unidimensional positives based on compound)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b52c38fc9cc1debdf8d76a081e411b75b266f8c9c62e44f6df99918effc85be8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
